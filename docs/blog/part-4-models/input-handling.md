---
title: Input Handling
---

## Overview

In this chapter we will design a framework for input event handling and an orbital camera controller.

Note there is no new Vulkan functionality introduced in this chapter.

---

## Input Events

### Rationale

Whilst we could simply use GLFW directly in our application (as we did for the ESCAPE key listener) there are compelling reasons to introduce a layer of abstraction:

* The GLFW API exposes some underlying details (such as window handle pointers) that we would prefer to hide if possible.

* Some events are implemented by GLFW as callback handlers e.g. `MousePositionListener` and others as query functions, e.g. `glfwGetJoystickAxes`.

* Several of the event types map to the same general forms - for example keyboard keys, mouse buttons and controller buttons are essentially equivalent.

* Traditional event callbacks violate the principle of separation of concerns by mixing application logic and the event handling code.

Based on these observations we enumerate the following requirements for our design:

* Map the various events to a smaller number of general types.

* Abstract over the underlying GLFW code for the handling of input events.

* Separate the event handling framework from the application logic.

* Provide a mechanism to map events to application logic that requires minimal configuration (or ideally none).

### Analysis

GLFW supports the following types of events:

type                    | arguments                     | device
----                    | ---------                     | ------
keyboard                | key, action, modifiers        | keyboard
mouse pointer           | x-y                           | mouse
mouse button            | button, action, modifiers     | mouse
mouse wheel             | value                         | mouse
window enter/leave      | boolean                       | window
window focus            | boolean                       | window
controller / joystick   | x-y                           | controller
controller button       | button, press/release         | controller
controller axis         | axis, value                   | controller
controller hat          | hat, press/release            | controller

Notes:

* A _controller_ is defined here as a joystick, gamepad, console controller, etc.

* There are several more but the above is enough to be getting on with.

After a bit of analysis we determine that the events can be generalised to the following:

type        | name      | parameterized | arguments     | examples                                          |
----        | ----      | ------------- | ---------     | --------                                          |
position    | no        | no            | x-y           | mouse pointer, controller                         |
button      | yes       | yes           | n/a           | keyboard, mouse buttons, controller buttons       |
axis        | yes       | no            | value         | mouse wheel, controller axis                      |
boolean     | no        | no            | boolean       | window                                            |

Where _name_ specifies whether the event has a specific name property and _parameterized_ indicates an event that has multiple values, e.g. keyboard key names.

### Framework

Based on the above we start with an abstraction for an event:

```java
public interface Event {
    /**
     * @return Type of event
     */
    Type<?> type();
}
```

An _event type_ specifies the static properties of the event:

```java
interface Type<T extends Event> {
    /**
     * @return Event name
     */
    String name();

    /**
     * @return Source of this type of event
     */
    Source source();
}
```

An event _source_ is a binding point for an _action handler_ that consumes events generated by that source:

```java
interface Source {
    /**
     * @return Device
     */
    Device device();

    /**
     * @return Types of events generated by this source
     */
    List<? extends Type<?>> types();

    /**
     * Binds the given handler to this source.
     * @param handler Event handler
     */
    void bind(Consumer<Event> handler);

    /**
     * Disables this source.
     */
    void disable();
}
```

Finally a _device_ is comprised of a number of event sources:

```java
interface Device {
    /**
     * @return Event sources
     */
    Set<Source> sources();

    /**
     * Closes this device.
     */
    void close();
}
```

The purpose of this framework is to:

* Provide a platform-independant mechanism to bind events to a handler (defined as a simple consumer).

* Enumerate the types of event generated by a source.

* Enumerate the event sources for a device.

### Template Implementation

As it turns out the _axis_ event type is probably the simplest case - we will implement an end-to-end solution for the mouse wheel axis.

We start with a template implementation for a GLFW device and event source, which we will then extend to support the mouse wheel.

The `DesktopDevice` encapsulates a reference to the underlying GLFW window:

```java
public abstract class DesktopDevice implements Device {
    private final Window window;

    @Override
    public void close() {
    }
}
```

We next implement a local, template class for a GLFW source belonging to this device:

```java
public abstract class DesktopSource<T> implements Source {
    @Override
    public final Device device() {
        return DesktopDevice.this;
    }

    @Override
    public final void bind(Consumer<Event> handler) {
        ...
    }

    @Override
    public final void disable() {
        ...
    }
}
```

A sub-class of this template is required to implement two methods to support registration of a GLFW listener.  The `listener` method creates a GLFW listener that is responsible for created an event and delegating to a given handler:

```java
/**
 * Creates a listener that generates events and delegates to the given handler.
 * @param handler Event handler
 * @return New GLFW listener
 */
protected abstract T listener(Consumer<Event> handler);
```

The `method` is a provider for the GLFW callback registration method for that listener (similar to how we return a destructor for a Vulkan object):

```java
/**
 * Returns the registration method for the listener.
 * @param lib GLFW library
 * @return Listener registration method
 */
protected abstract BiConsumer<Window, T> method(DesktopLibrary lib);
```

The process of binding a general event handler to a GLFW-specific source is:

1. Create a GLFW listener that delegates to the general event handler via the `listener` method.

2. Retrieve the GLFW callback registration `method` for this listener.

3. Invoke the callback method with the parent window and listener.

This is implemented by the following helper:

```java
private void register(T listener) {
    DesktopLibrary lib = window.desktop().library();
    BiConsumer<Window, T> method = method(lib);
    method.accept(window, listener);
    this.listener = listener;
}
```

Note that the `register` method keeps a reference to the generated GLFW listener:

```java
public abstract class DesktopSource<T> implements Source {
    @SuppressWarnings("unused")
    private T listener;
}
```

This prevents GLFW de-registering a garbage collected listener that is still 'active', i.e. the `listener` argument is out-of-scope at the end of the method.

We can now implement the public methods in terms of the new helper functionality:

```java
@Override
public final void bind(Consumer<Event> handler) {
    T listener = listener(handler);
    register(listener);
}

@Override
public final void disable() {
    register(null);
}
```

Finally we add the mouse device as a lazily instantiated member of the window:

```java
public class Window {
    private final Supplier<MouseDevice> mouse = new LazySupplier<>(() -> new MouseDevice(this));

    public MouseDevice mouse() {
        return mouse.get();
    }
}
```

> Apparently GLFW version 4 will deprecate callbacks in favour of query methods but we will cross that bridge if and when we upgrade the native library.

### Axis

We next define a general class representing an axis and its associated events:

```java
public record Axis(String name, Source source) implements Type<AxisEvent> {
    public class AxisEvent implements Event {
        private final float value;

        public AxisEvent(float value) {
            this.value = value;
        }

        @Override
        public Type<AxisEvent> type() {
            return Axis.this;
        }

        public float value() {
            return value;
        }
    }
}
```

We can now create a GLFW-specific device with an event source for the mouse-wheel:

```java
public class MouseDevice extends DesktopDevice {
    private final MouseWheel wheel = new MouseWheel();

    @Override
    public Set<Source> sources() {
        return Set.of(wheel);
    }

    public Axis wheel() {
        return wheel.axis;
    }
}
```

The `MouseWheel` is a GLFW event source comprising a single axis for the mouse-wheel:

```java
private class MouseWheel extends DesktopSource<MouseScrollListener> {
    private final Axis axis = new Axis("Wheel", this);

    @Override
    public List<Axis> types() {
        return List.of(axis);
    }
}
```

The `listener` factory creates a GLFW mouse-wheel listener which wraps up the event and delegates it to the handler:

```java
protected MouseScrollListener listener(Consumer<Event> handler) {
    return (ptr, x, y) -> {
        Event e = axis.new AxisEvent((float) y);
        handler.accept(e);
    };
}
```

Finally we specify the callback registration method for the GLFW mouse-wheel:

```java
protected BiConsumer<Window, MouseScrollListener> method(DesktopLibrary lib) {
    return lib::glfwSetScrollCallback;
}
```

Notes:

* The GLFW listener for the mouse-wheel has X and Y arguments (with the same values) but we only use one.

* We also expose the mouse-wheel axis for convenience.

### Position

The next type of event is a _position_ that represents an event source for X-Y location events, we will implement this to support mouse movement events.

The position event type follows the same pattern as the axis:

```java
public record Position(String name, Source source) implements Type<PositionEvent> {
    public class PositionEvent implements Event {
        public final float x, y;

        @Override
        public Type<?> type() {
            return Position.this;
        }
    }
}
```

We use the same framework to implement an event source for the mouse pointer:

```java
private class MousePointer extends DesktopSource<MousePositionListener> {
    private final Position pointer = new Position("Pointer", this);

    @Override
    public List<Position> types() {
        return List.of(pointer);
    }

    @Override
    protected MousePositionListener listener(Consumer<Event> handler) {
        return (ptr, x, y) -> {
            PositionEvent pos = pointer.new PositionEvent((float) x, (float) y);
            handler.accept(pos);
        };
    }

    @Override
    protected BiConsumer<Window, MousePositionListener> method(DesktopLibrary lib) {
        return lib::glfwSetCursorPosCallback;
    }
}
```

Which is added to the mouse device:

```java
public class MouseDevice extends DesktopDevice {
    ...
    private final MousePointer ptr = new MousePointer();

    @Override
    public Set<Source> sources() {
        return Set.of(ptr, wheel);
    }

    public Position pointer() {
        return ptr.pointer;
    }
}
```

### Buttons

The final type of event (for now) is a _button_ that represents keyboard keys, mouse buttons, joystick hats, etc:

```java
public record Button(String id, Source source, Action action, int mods) implements Type<Button>, Event {
    @Override
    public final Type<?> type() {
        return this;
    }
}
```

Notes:

* A button also has an _action_ and a _keyboard modifiers_ mask.

* A button is also its own event type since there are no additional arguments (unlike the axis or position events).

An action is a simple enumeration based on the GLFW action codes:

```java
public enum Action {
    RELEASE,
    PRESS,
    REPEAT
}
```

Similarly for the keyboard modifiers:

```java
public enum Modifier implements IntegerEnumeration {
    SHIFT(0x0001),
    CONTROL(0x0002),
    ALT(0x0004),
    SUPER(0x0008),
    CAPS_LOCK(0x0010),
    NUM_LOCK(0x0020)
}
```

The _name_ of the button is constructed on demand:

```java
public String name() {
    String modifiers = modifiers().stream().map(Enum::name).collect(joining(Event.DELIMITER));
    return Event.name(id, action.name(), modifiers);
}
```

The following helper is added to the event class to build a hyphen-delimited name from a list of tokens:

```java
String DELIMITER = "-";

static String name(String... tokens) {
    return Arrays
        .stream(tokens)
        .filter(Predicate.not(String::isEmpty))
        .collect(joining(DELIMITER));
}
```

Finally we also provide a convenience constructor that generates the _default_ definition of a button:

```java
public Button(String id, Source source) {
    this(id, source, Action.PRESS, 0);
}
```

And the following factory method that derives a button with specific action and keyboard modifiers:

```java
public Button resolve(Action action, int mods) {
    return new Button(id, source, action, mods);
}
```

The event source implementation for the GLFW mouse device first generates the list of buttons:

```java
private class MouseButton extends DesktopSource<MouseButtonListener> {
    private final String prefix = Event.name("Mouse", "Button");
    
    private final List<Button> buttons = IntStream
        .rangeClosed(1, MouseInfo.getNumberOfButtons())
        .mapToObj(String::valueOf)
        .map(id -> Event.name(prefix, id))
        .map(name -> new Button(name, this))
        .collect(toList());
    
    @Override
    public List<Button> types() {
        return buttons;
    }
}
```

Surprisingly GLFW does not seem to provide any means of determining the number of mouse buttons supported by the hardware, for the moment we use the an AWT method.  However this means that we need to override the default Spring application behaviour which creates a _headless_ application by default (otherwise the AWT method throws an exception):

```java
new SpringApplicationBuilder(ModelDemo.class)
    .headless(false)
    .run(args);
```

The GLFW listener implementation looks up a mouse button by index and uses the `resolve` method to apply the action and keyboard modifiers:

```java
private class MouseButton extends DesktopSource<MouseButtonListener> {
    @Override
    protected MouseButtonListener listener(Consumer<Event> handler) {
        return (ptr, index, action, mods) -> {
            Button button = buttons.get(index);
            Button event = button.resolve(DesktopDevice.map(action), mods);
            handler.accept(event);
        };
    }
    
    @Override
    protected BiConsumer<Window, MouseButtonListener> method(DesktopLibrary lib) {
        return lib::glfwSetMouseButtonCallback;
    }
}
```

In this case since mouse buttons are _parameterized_ we expose the source itself:

```java
public class MouseDevice extends DesktopDevice {
    ...
    private final MouseButton buttons = new MouseButton();

    public DesktopSource<?> buttons() {
        return buttons;
    }
    
    @Override
    public Set<Source> sources() {
        return Set.of(ptr, buttons, wheel);
    }
}
```

We also add a helper to map a GLFW action code to the enumeration:

```java
protected static Action map(int action) {
    return switch(action) {
        case 0 -> Action.RELEASE;
        case 1 -> Action.PRESS;
        case 2 -> Action.REPEAT;
        default -> throw new RuntimeException("Unsupported action code: " + action);
    };
}
```

### Keyboard

The final device we will implement in this chapter is the GLFW keyboard:

```java
public class KeyboardDevice extends DesktopDevice {
    private final KeyboardSource keyboard = new KeyboardSource();

    public DesktopSource<?> source() {
        return keyboard;
    }

    @Override
    public Set<Source> sources() {
        return Set.of(keyboard);
    }
}
```

The keyboard source is implemented as follows:

```java
private class KeyboardSource extends DesktopSource<KeyListener> {
    @Override
    public List<Type<?>> types() {
        return List.of();
    }

    @Override
    protected KeyListener listener(Consumer<Event> handler) {
        ...
    }

    @Override
    protected BiConsumer<Window, KeyListener> method(DesktopLibrary lib) {
        return lib::glfwSetKeyCallback;
    }
}
```

The listener implementation caches the button definition for keyboard keys:

```java
private class KeyboardSource extends DesktopSource<KeyListener> {
    private final Map<Integer, Button> keys = new HashMap<>();

    @Override
    protected KeyListener listener(Consumer<Event> handler) {
        return (ptr, key, scancode, action, mods) -> {
            Button base = keys.computeIfAbsent(key, this::button);
            Button button = base.resolve(DesktopDevice.map(action), mods);
            handler.accept(button);
        };
    }
}
```

A new key definition is created by the following helper:

```java
private Button button(int key) {
    String name = TABLE.get(key);
    if(name == null) throw new RuntimeException("Unknown key code: " + key);
    return new Button(name, KeyboardSource.this);
}
```

Where `TABLE` maps GLFW key codes to key names specified by a local resource (loader not shown).  The key table is a simple text file illustrated in the following fragment:

```
SPACE              32
APOSTROPHE         39
COMMA              44
```

Notes:

* The `types` for the keyboard source is empty since we assume applications will generally refer to keys by name.

* GLFW also provides a _scancode_ argument and the `glfwGetKeyName` API method but this functionality only seems to support a subset of the expected keys.

* At the time of writing `TABLE` is hidden as we assume that the GLFW key-codes will not be required outside the framework.

* We add the lazily-instantiated keyboard device to the GLFW window.

---

## Action Bindings

### Overview

Using this framework we can now bind event sources to handlers, for example:

```java
// Retrieve devices
Mouse mouse = window.mouse();
Keyboard keyboard = window.keyboard();

// Bind stop event
Consumer<Event> kb = e -> {
    ButtonEvent button = (ButtonEvent) e;
    if(button.name().startsWith("ESCAPE")) {
        app.stop();
    }
}
keyboard.bind(kb);

// Bind mouse-wheel handler
Consumer<Event> handler = e -> {
    AxisEvent axis = (AxisEvent) e;
    ...
};
wheel.bind(handler);
```

However there are still problems with this approach:

* We are required to cast the event if we want to use the sub-class properties.

* Ideally we would prefer to bind specific _parameterized_ events (especially for the keyboard, e.g. for the ESCAPE handler) rather than having to implement switching logic.

* Additionally we would also like to be able to bind directly to a method reference with an appropriate signature instead of hand-crafting adapters or messy lambdas.

We _could_ refactor the event class to contain the properties for __all__ cases but this is pretty ugly (even if there are only a handful).  Alternatively we could implement some sort of double-dispatch to transform a base-class event to its sub-type but that also feels overkill in this case.

### Bindings

Instead we introduce the _action bindings_ class which is essentially a bi-directional mapping of events to/from handlers:

```java
public class ActionBindings implements Consumer<Event> {
    private final Map<Type<?>, Consumer<Event>> bindings = new HashMap<>();
    private final Map<Object, Set<Type<?>>> map = new HashMap<>();
}
```

The bindings class is itself an event handler:

```java
@Override
public void accept(Event e) {
    Consumer<Event> handler = bindings.get(e.type());
    if(handler != null) {
        handler.accept(e);
    }
}
```

The following generic method binds an arbitrary event type to/from an event handler:

```java
public <T extends Event> void bind(Type<T> type, Consumer<? extends T> handler) {
    // Lookup or create reverse mapping
    var types = map.computeIfAbsent(handler, ignored -> new HashSet<>());

    // Add binding
    bindings.put(type, (Consumer<Event>) consumer);
    types.add(type);
}
```

Note that this method is type-safe at compile-time but down-casts the handler to the base-class event.

We add accessors to retrieve the handler for a given type of event:

```java
public Optional<Consumer<? extends Event>> binding(Type<?> type) {
    return Optional.ofNullable(bindings.get(type));
}
```

And to retrieve the reverse mapping of event types for a given handler:

```java
public Stream<Type<?>> bindings(Consumer<? extends Event> handler) {
    var types = map.get(handler);
    if(types == null) throw new IllegalArgumentException(...);
    return types.stream();
}
```

We also add support (not shown) to remove bindings by handler or event type and to clear all bindings.

### Binding Support

We can now implement convenience methods to bind specific types of event to a method with the appropriate signature.

Generally buttons events will be bound to a `void` method without any parameters which is wrapped by an adapter:

```java
public Consumer<Button> bind(Type<Button> type, Runnable method) {
    Consumer<Button> handler = ignored -> method.run();
    bind(type, handler);
    return handler;
}
```

Next we add the following interface defining a method that accepts a floating-point X-Y position:

```java
public class Position {
    @FunctionalInterface
    public interface PositionHandler {
        void handle(float x, float y);
    }
}
```

Which is used in a second bind variant for position events:

```java
public Consumer<PositionEvent> bind(Type<PositionEvent> type, PositionHandler adapter) {
    Consumer<PositionEvent> handler = e -> adapter.handle(e.x, e.y);
    bind(type, handler);
    return handler;
}
```

Finally we define a similar bind variant and abstraction for an axis event:

```java
@FunctionalInterface
public interface AxisHandler {
    void handle(float value);
}
```

### Conclusion

A final enhancement is to automatically initialise the sources used in the bindings:

```java
public void init() {
    bindings
        .keySet()
        .stream()
        .map(Type::source)
        .distinct()
        .forEach(src -> src.bind(this));
}
```

The example above can now be refactored using the new class:

```java
// Bind stop event
ActionBindings bindings = new ActionBindings();
Source keyboard = window.keyboard().source();
bindings.bind(new Button("ESCAPE", keyboard), app::stop);

// Bind mouse-wheel handler
AxisHandler handler = e -> ...
bindings.bind(window.mouse().wheel(), handler);

// Init
bindings.init();
```

The new event handling framework and the action bindings class should satisfy the requirements we identified at the start of the chapter:

* The GLFW specifics are now abstracted away (and theoretically could be replaced by an alternative implementation).

* The event-handling logic is separated from the application code, e.g. binding ESCAPE to the stop method.

* Binding events to handlers or methods is relatively concise and does not require any casting or switching logic.

So far we have only implemented events that are based on GLFW callbacks - we will address devices that use query methods later (such as a controller or joystick).

---

## Camera Controller

### Default Implementation

The camera class is a simple model class, to implement richer functionality we will introduce a _camera controller_ that can be bound to input actions.

We first implement a basic _free-look_ controller that rotates the scene about the cameras position:

```java
public class DefaultCameraController {
    private final Camera cam;
    private final Dimensions dim;
    
    public void update(float x, float y) {
        ...
    }
}
```

The `update` method accepts an X-Y coordinate relative to the specified viewport dimensions, e.g. the mouse pointer location.

The view direction of the free-look camera is determined as follows:

1. Map the coordinates to yaw-pitch angles.

2. Calculate a point on the unit-sphere given these angles.

3. Point the camera in the direction of the calculated point.

To transform the coordinates to yaw-pitch angles we add the _interpolator_ class:

```java
@FunctionalInterface
public interface Interpolator {
    /**
     * Applies this interpolator to the given value.
     * @param value Value to be interpolated (assumes normalized)
     * @return Interpolated value
     */
    float interpolate(float t);
    
    static Interpolator linear(float start, float end) {
        float range = end - start;
        return t -> lerp(start, range, t);
    }

    static float lerp(float start, float range, float value) {
        return start + value * range;
    }
}
```

We can now add two interpolators to the controller:

```java
private final Interpolator horizontal = Interpolator.linear(0, TWO_PI);
private final Interpolator vertical = Interpolator.linear(-HALF_PI, HALF_PI);
```

Notes:

* The ranges of the interpolators are dependant on the algorithm to calculate the point on the unit-sphere (see below).

* We may later choose to allow the range of the two interpolators to be mutable values, i.e. currently we assume the range is the entire viewport.

* The interpolator class will be expanded with additional functionality in subsequent chapters.

### Unit Sphere

To calculate the point on the unit-sphere we add another new helper class:

```java
public final class Sphere {
    public interface PointFactory {
        /**
         * Calculates the point on the unit-sphere for the given rotation angles (in radians).
         * @param theta     Horizontal angle (or <i>yaw</i>) in the range zero to {@link MathsUtil#TWO_PI}
         * @param phi       Vertical angle (or <i>pitch</i>) in the range +/- {@link MathsUtil#HALF_PI}
         * @return Unit-sphere surface point
         */
        Point point(float theta, float phi);
    }
}
```

The default implementation of the factory method is relatively straight-forward:

```java
PointFactory DEFAULT = (theta, phi) -> {
    final float cos = cos(phi);
    final float x = cos(theta) * cos;
    final float y = sin(theta) * cos;
    final float z = sin(phi);
    return new Point(x, y, z);
};
```

This implementation is based on the standard algorithm for calculating a point on a sphere, however the _coordinate space_ of the generated points is not aligned with the Vulkan system:

1. A horizontal (theta) angle of zero points in the direction of the X axis whereas we generally require the default to be the negative Z axis.

2. The Y and Z axes are transposed, i.e. Z is _up_ in the default implementation of the algorithm.

For these reasons we implement the algorithm as an interface so we can provide adapters to transform the coordinate space, rather than butchering the algorithm or forcing the client to pass option flags into the method.

To make the camera point in the negative Z direction we simply fiddle the angle with a 90 degree clockwise 'rotation':

```java
default PointFactory rotate() {
    return (theta, phi) -> point(theta - MathsUtil.HALF_PI, phi);
}
```

To transpose the axes we create an adapter to swizzle the Y and Z components of the calculated point:

```java
default PointFactory swizzle() {
    return (theta, phi) -> {
        final Point pt = point(theta, phi);
        return new Point(pt.x, pt.z, pt.y);
    };
}
```

Note that both these adapters are `default` interface methods which allow us to create the desired factory as follows:

```java
public class DefaultCameraController {
    ...
    private final PointFactory sphere = PointFactory.DEFAULT.swizzle().rotate();
}
```

In the unit-test for the new sphere class we use a `spy` to create a mock that automatically implements the default methods:

```java
public class SphereTest {
    @Nested
    class PointFactoryTests {
        @Test
        void rotate() {
            PointFactory factory = spy(PointFactory.class);
            PointFactory rotate = factory.rotate();
            assertNotNull(rotate);
            rotate.point(0, 0);
            verify(factory).point(-HALF_PI, 0);
        }
    }
}
```

Finally we can implement the controller update method to point the camera at the calculated point on the sphere:

```java
public void update(float x, float y) {
    float yaw = horizontal.interpolate(x / dim.width());
    float pitch = vertical.interpolate(y / dim.height());
    Point pt = sphere.point(yaw, pitch);
    cam.direction(new Vector(pt));
}
```

### Orbital Controller

An _orbital_ (or arcball) camera controller rotates the view position _about_ a target point-of-interest.

We first extend the default controller to include the target position and a _radius_ which is the distance from the camera:

```java
public class OrbitalCameraController extends DefaultCameraController {
    private Point target = Point.ORIGIN;
    private float radius = 1;

    public OrbitalCameraController(Camera cam, Dimensions dim) {
        super(cam, dim);
        cam.look(target);
    }
}
```

The algorithm to calculate the position of the camera is the same as the default controller except for the final step, we therefore refactor the base-class by factoring out the code that updates the camera to a local helper:

```java
public void update(float x, float y) {
    ...
    Point pt = sphere.point(yaw, pitch);
    update(pt);
}

protected void update(Point pos) {
    cam.direction(new Vector(pos));
}
```

In the orbital implementation we can now implement the local `update` method to move the camera to the calculated point on the sphere and then point it at the target:

```java
@Override
protected void update(Point pt) {
    Point pos = pt.scale(radius).add(target);
    cam.move(pos);
    cam.look(target);
}
```

The orbital controller provides mutators (not shown) to set the radius and target, and to clamp the radius to a min/max range (to prevent the camera being moved to the target position).

The orbital camera can also be _zoomed_ towards or away from the target:

```java
public void zoom(float inc) {
    radius = MathsUtil.clamp(radius - inc * scale, min, max);
    Vector pos = cam.direction().multiply(radius);
    cam.move(target.add(pos));
}
```

Note that the increment is _subtracted_ from the radius.

---

## Integration

To integrate the new event framework and camera controller we add the following to the camera configuration class:

```java
public class CameraConfiguration {
    private final Matrix projection;
    private final Camera cam = new Camera();
    private final OrbitalCameraController controller;

    public CameraConfiguration(Swapchain swapchain) {
        projection = Projection.DEFAULT.matrix(0.1f, 100, swapchain.extents());
        controller = new OrbitalCameraController(cam, swapchain.extents());
        controller.radius(3);
        controller.scale(0.25f);
    }
}
```

Next we add a new component to instantiate the action bindings:

```java
@Bean
public ActionBindings bindings(Window window, RenderLoop loop) {
    ActionBindings bindings = new ActionBindings();
    ...
    bindings.init();
    return bindings;
}
```

The ESCAPE key is bound to the `stop` method of the render loop:

```java
var keyboard = window.keyboard().source();
bindings.bind(new Button("ESCAPE", keyboard), loop::stop);
```

And the mouse pointer and wheel are bound to the relevant methods on the controller:

```java
MouseDevice mouse = window.mouse();
bindings.bind(mouse.pointer(), controller::update);
bindings.bind(mouse.wheel(), controller::zoom);
```

Finally we modify the matrix bean to apply the local rotation to the chalet model and to calculate the final projection matrix:

```java
@Bean
public Task matrix(VulkanBuffer uniform) {
    Matrix x = Rotation.matrix(Vector.X, MathsUtil.toRadians(90));
    Matrix y = Rotation.matrix(Vector.Y, MathsUtil.toRadians(-120));
    Matrix model = y.multiply(x);

    return () -> {
        final Matrix matrix = projection.multiply(cam.matrix()).multiply(model);
        uniform.load(matrix);
    };
}
```

When we run the application we should now be able to use the mouse to look around the chalet model and zoom in using the scroll wheel.  Nice.

---

## Summary

In this chapter we implemented:

* A generic input event framework that abstracts over the underlying GLFW implementation.

* The action bindings class that aids separation of concerns for input events and application action handlers.

* A free-look and orbital camera controller.

