---
title: Input Handling
---

## Overview

In this chapter we will design a framework for input event handling and implement an orbital camera controller.

Note there is no new Vulkan functionality introduced in this chapter.

---

## Input Events

### Rationale

Whilst we could simply use GLFW directly in our application (as we did for the ESCAPE key listener) there are compelling reasons to introduce a layer of abstraction:

* The GLFW API exposes some underlying details (such as window handle pointers) that we would prefer to hide if possible.

* Some events are implemented by GLFW as callback handlers e.g. `MousePositionListener` and others as query functions, e.g. `glfwGetJoystickAxes`.

* Several of the GLFW events are essentially equivalent (e.g. keyboard keys and mouse buttons) but are implemented using different listeners and API calls.

* Traditional event callbacks violate the principle of separation of concerns by mixing application logic and the event handling code.

Based on these observations we enumerate the following requirements for our design:

* Map the various events to a smaller number of general types.

* Abstract over the underlying GLFW listeners and API.

* Separate the event handling framework from the application logic.

* Provide a mechanism to map events to application logic that requires minimal configuration (or ideally none).

### Analysis

GLFW supports the following types of events:

type                    | arguments                     | device
----                    | ---------                     | ------
keyboard                | key, action, modifiers        | keyboard
mouse pointer           | x-y                           | mouse
mouse button            | button, action, modifiers     | mouse
mouse wheel             | value                         | mouse
window enter/leave      | boolean                       | window
window focus            | boolean                       | window
controller / joystick   | x-y                           | controller
controller button       | button, press/release         | controller
controller axis         | axis, value                   | controller
controller hat          | hat, press/release            | controller

Notes:

* A _controller_ is defined here as a joystick, gamepad, console controller, etc.

* There are several more but the above is enough to be getting on with.

After a bit of analysis we determine that the events can be generalised to the following:

type        | name      | parameterized | arguments     | examples                                          |
----        | ----      | ------------- | ---------     | --------                                          |
position    | no        | no            | x-y           | mouse pointer, controller                         |
button      | yes       | yes           | n/a           | keyboard, mouse buttons, controller buttons       |
axis        | yes       | no            | value         | mouse wheel, controller axis                      |
boolean     | no        | no            | boolean       | window                                            |

Where _name_ specifies whether the event has a specific name property and _parameterized_ indicates an event that has multiple values, e.g. mouse buttons.

> Apparently GLFW version 4 will deprecate callbacks in favour of query methods but we will cross that bridge if and when we upgrade the native library.

### Framework

Based on the above we start with an abstraction for an event:

```java
public interface Event {
    /**
     * @return Type discriminator for this event
     */
    Object type();
}
```

The purpose of the `type` discriminator is covered later.

An event _source_ is a binding point for an _action handler_ that consumes events generated by that source:

```java
interface Source<T extends Event> {
    /**
     * Binds the given handler to this source.
     * @param handler Event handler
     */
    void bind(Consumer<Event> handler);
}
```

Finally a _device_ is comprised of a number of event sources:

```java
interface Device {
    /**
     * @return Event sources
     */
    Set<Source> sources();
}
```

The purpose of this framework is to:

* Generalise the definition of an input event.

* Provide a platform-independant mechanism to bind events to a single handler abstraction (defined as a simple consumer).

* Allow an application to programatically enumerate the events that can be generated by a device.

### Template Implementation

An _axis_ is an input device that generates a ranged value, such as the mouse wheel or a HOTAS throttle.  As it turns out this is probably the simplest event case, we will implement an end-to-end solution for the mouse wheel axis.

First we define a template implementation for a GLFW based device and event source:

```java
public abstract class DesktopDevice implements Device {
    private final Window window;

    @Override
    public void close() {
    }
}
```

A GLFW event source is an inner template:

```java
public abstract class DesktopSource<T> implements Source {
    @Override
    public final void bind(Consumer<Event> handler) {
        ...
    }

    /**
     * Creates a listener that generates events and delegates to the given handler.
     * @param handler Event handler
     * @return New GLFW listener
     */
    protected abstract T listener(Consumer<Event> handler);

    /**
     * Provides the registration method for the listener.
     * @param lib GLFW library
     * @return Listener registration method
     */
    protected abstract BiConsumer<Window, T> method(DesktopLibrary lib);
}
```

Where `listener` creates a GLFW listener responsible for delegating events to a given handler and `method` is a provider for the GLFW registration method for that listener (similar to how Vulkan objects provide a destructor method):

The process of binding an event handler to a GLFW-specific source is:

1. Create a GLFW listener that delegates to the general event handler via the `listener` method.

2. Retrieve the GLFW callback registration `method` for this listener.

3. Invoke the callback method with the parent window and listener.

This is implemented by the following helper:

```java
private void bind(T listener) {
    DesktopLibrary lib = window.desktop().library();
    BiConsumer<Window, T> method = method(lib);
    method.accept(window, listener);
    this.listener = listener;
}
```

Which is used in the public method to bind a handler:

```java
public final void bind(Consumer<Event> handler) {
    if(handler == null) {
        bind((T) null);
    }
    else {
        bind(listener(handler));
    }
}
```

Note that the active listener is a member of the class:

```java
public abstract class DesktopSource<T> implements Source {
    @SuppressWarnings("unused")
    private T listener;
}
```

This prevents an 'active' listener from being garbage collected and de-registered by GLFW, i.e. the `listener` argument is out-of-scope at the end of the helper method.

### Axis

An _axis_ is an event source with a companion class for the associated events:

```java
public interface Axis extends Source {
    record AxisEvent(Axis axis, float value) implements Event {
        @Override
        public Object type() {
            return axis;
        }
    }
}
```

We next create a GLFW device with an event source for the mouse-wheel:

```java
public class MouseDevice extends DesktopDevice {
    private final MouseWheel wheel = new MouseWheel();

    @Override
    public Set<Source> sources() {
        return Set.of(wheel);
    }

    public Axis wheel() {
        return wheel;
    }
}
```

The mouse wheel is a GLFW axis event source:

```java
private class MouseWheel extends DesktopSource<MouseScrollListener> implements Axis {
    @Override
    protected MouseScrollListener listener(Consumer<Event> handler) {
        return (ptr, x, y) -> {
            AxisEvent e = new AxisEvent(this, (float) y);
            handler.accept(e);
        };
    }

    @Override
    protected BiConsumer<Window, MouseScrollListener> method(DesktopLibrary lib) {
        return lib::glfwSetScrollCallback;
    }
}
```

Notes:

* The GLFW listener for the mouse-wheel has X and Y arguments (with the same values) but we only use one.

* We also expose the mouse-wheel axis for convenience.

Finally we add the mouse device as a lazily instantiated member of the window:

```java
public class Window {
    private final Supplier<MouseDevice> mouse = new LazySupplier<>(() -> new MouseDevice(this));

    public MouseDevice mouse() {
        return mouse.get();
    }
}
```

### Position

The next type of event is a _position_ that represents X-Y location events such as mouse pointer movement:

```java
public record PositionEvent(Source source, float x, float y) implements Event {
    @Override
    public Object type() {
        return source;
    }
}
```

We use the same framework to implement a position event source for the mouse pointer:

```java
private class MousePointer extends DesktopSource<MousePositionListener> {
    @Override
    protected MousePositionListener listener(Consumer<Event> handler) {
        return (ptr, x, y) -> {
            PositionEvent pos = new PositionEvent(this, (float) x, (float) y);
            handler.accept(pos);
        };
    }

    @Override
    protected BiConsumer<Window, MousePositionListener> method(DesktopLibrary lib) {
        return lib::glfwSetCursorPosCallback;
    }
}
```

Which is also added to the mouse device:

```java
public class MouseDevice extends DesktopDevice {
    ...
    private final MousePointer ptr = new MousePointer();

    @Override
    public Set<Source> sources() {
        return Set.of(ptr, wheel);
    }

    public Position pointer() {
        return ptr.pointer;
    }
}
```

### Buttons

The final type of event (for now) is a _button_ that represents keyboard keys, mouse buttons, joystick hats, etc:

```java
public class Button implements Event {
    private final String id;
    private final String name;
    private final Action action;
    private final int mods;

    @Override
    public Object type() {
        return this;
    }
}
```

Notes:

* A button also has an _action_ and a _keyboard modifiers_ mask.

* A button is also its own event type since there are no additional arguments (unlike the axis or position events).

An action is a simple enumeration based on the GLFW action codes:

```java
public enum Action {
    RELEASE,
    PRESS,
    REPEAT
}
```

Similarly for the keyboard modifiers:

```java
public enum Modifier implements IntegerEnumeration {
    SHIFT(0x0001),
    CONTROL(0x0002),
    ALT(0x0004),
    SUPER(0x0008),
    CAPS_LOCK(0x0010),
    NUM_LOCK(0x0020)
}
```

The _name_ of the button is built in the constructor by the following method:

```java
private String build() {
    String modifiers = name(modifiers().toArray());
    return name(id, action.name(), modifiers);
}
```

Which uses the following new helper method to construct a hyphen-delimited name:

```java
public static String name(Object... tokens) {
    return Arrays
        .stream(tokens)
        .map(String::valueOf)
        .collect(joining(DELIMITER));
}
```

Finally we also provide a convenience constructor that generates the _default_ definition of a button:

```java
public Button(String id, Source source) {
    this(id, source, Action.PRESS, 0);
}
```

And the following factory method that derives a button with specific action and keyboard modifiers:

```java
public Button resolve(Action action, int mods) {
    return new Button(id, source, action, mods);
}
```

The event source implementation for the mouse device first generates the list of buttons:

```java
private class MouseButton extends DesktopSource<MouseButtonListener> {
    private final List<Button> buttons = IntStream
        .rangeClosed(1, MouseInfo.getNumberOfButtons())
        .mapToObj(id -> Button.name("Mouse", id))
        .map(Button::new)
        .collect(toList());
}
```

Surprisingly GLFW does not seem to provide any means of determining the number of mouse buttons supported by the hardware, for the moment we use an AWT method.  However this means that we need to override the default Spring application behaviour which creates a _headless_ application by default (otherwise the AWT method throws an exception):

```java
new SpringApplicationBuilder(ModelDemo.class)
    .headless(false)
    .run(args);
```

The mouse buttons event source looks up a button by index and uses the `resolve` method to apply the action and keyboard modifiers:

```java
private class MouseButton extends DesktopSource<MouseButtonListener> {
    private final List<Button> buttons = ...

    @Override
    protected MouseButtonListener listener(Consumer<Event> handler) {
        return (ptr, index, action, mods) -> {
            Button button = buttons.get(index);
            Button event = button.resolve(DesktopDevice.map(action), mods);
            handler.accept(event);
        };
    }

    @Override
    protected BiConsumer<Window, MouseButtonListener> method(DesktopLibrary lib) {
        return lib::glfwSetMouseButtonCallback;
    }
}
```

Finally we add a helper to map a GLFW action code to the enumeration:

```java
protected static Action map(int action) {
    return switch(action) {
        case 0 -> Action.RELEASE;
        case 1 -> Action.PRESS;
        case 2 -> Action.REPEAT;
        default -> throw new RuntimeException("Unsupported action code: " + action);
    };
}
```

### Keyboard

The final device we will implement in this chapter is the GLFW keyboard:

```java
public class KeyboardDevice extends DesktopDevice {
    private final KeyboardSource keyboard = new KeyboardSource();

    @Override
    public Set<Source> sources() {
        return Set.of(keyboard);
    }
}
```

The keyboard source caches button definitions:

```java
private class KeyboardSource extends DesktopSource<KeyListener> {
    @Override
    protected KeyListener listener(Consumer<Event> handler) {
        return (ptr, key, scancode, action, mods) -> {
            Button base = keys.computeIfAbsent(key, this::key);
            Button button = base.resolve(DesktopDevice.map(action), mods);
            handler.accept(button);
        };
    }
    
    @Override
    protected BiConsumer<Window, KeyListener> method(DesktopLibrary lib) {
        return lib::glfwSetKeyCallback;
    }
}
```

New key definitions are created by the following helper:

```java
private Button key(int code) {
    return new Button(table.name(code), this);
}
```

Where `table` maps GLFW key codes to key names specified by a resource file (loader not shown) which is a simple text file illustrated in the following fragment:

```
SPACE              32
APOSTROPHE         39
COMMA              44
```

Notes:

* GLFW also provides a _scancode_ argument and the `glfwGetKeyName` API method but this functionality only seems to support a subset of the expected keys.

* The key table is hidden but we provide a factory method to lookup keys by name.

* We add the lazily-instantiated keyboard device to the GLFW window.

---

## Action Bindings

### Overview

Using this framework we could now bind event sources to an action handler, however there are still several problems:

* Each type of event is a separate class so application code would be forced to cast events to access the sub-class properties.

* Ideally we would prefer to bind _parameterized_ events rather than having to implement switching logic (especially for the keyboard).

* Additionally we would also like to be able to bind directly to a method reference with an appropriate signature instead of hand-crafting adapters or messy lambdas.

We _could_ refactor the event class to contain the properties for __all__ cases but this is pretty ugly (even if there are only a handful).  Alternatively we could implement some sort of double-dispatch to transform a base-class event to its sub-type but that also feels overkill in this case.

Instead we will introduce an _action bindings_ class which is responsible for mapping events to handlers (or methods) and encapsulates any switching logic and type casting.

### Bindings

The action bindings is essentially a bi-directional mapping of events to/from handlers:

```java
public class ActionBindings implements Consumer<Event> {
    private final Map<Object, Consumer<Event>> bindings = new HashMap<>();
    private final Map<Consumer<? extends Event>, Set<Object>> handlers = new HashMap<>();
}
```

Note that the bindings class is itself an event handler.

The event `type` discriminator is used as the _key_ for the bindings mapping:

```java
@Override
public void accept(Event e) {
    Consumer<Event> handler = bindings.get(e.type());
    if(handler != null) {
        handler.accept(e);
    }
}
```

We add accessors to retrieve the handler for a given type of event:

```java
public Optional<Consumer<? extends Event>> binding(Object type) {
    return Optional.ofNullable(bindings.get(type));
}
```

And to retrieve the reverse mapping of event types for a given handler:

```java
public Stream<Object> bindings(Consumer<? extends Event> handler) {
    return handlers.get(handler).stream();
}
```

We also add support (not shown) to remove bindings by handler or event type and to clear all bindings.

### Binding Support

The following generic method binds an arbitrary event type to/from an event handler:

```java
private <T extends Event> void bindLocal(Object type, Consumer<? extends T> handler) {
    // Lookup or create reverse mapping
    Set<Object> types = handlers.computeIfAbsent(handler, ignored -> new HashSet<>());

    // Add binding
    @SuppressWarnings("unchecked")
    Consumer<Event> consumer = (Consumer<Event>) handler;
    bindings.put(type, consumer);
    types.add(type);
}
```

Note that this method is type-safe at compile-time but down-casts the handler to the base-class event.

This helper is used to bind an arbitrary event _source_ to a handler:

```java
public <T extends Event> void bind(Source<T> src, Consumer<T> handler) {
    bindLocal(src, handler);
    src.bind(this);
}
```

Note that we also automatically bind the event source to the bindings.

Next we implement convenience methods to bind specific types of event to methods with the appropriate signature.

Generally button events will be bound to a `void` method without any parameters:

```java
public void bind(Button button, Runnable handler) {
    Consumer<Button> adapter = ignored -> handler.run();
    bindLocal(button.type(), adapter);
}
```

For position events we define the following interface:

```java
public class PositionEvent {
    @FunctionalInterface
    public interface Handler {
        void handle(float x, float y);
    }
}
```

Which is used in a second bind variant for position events:

```java
public void bind(Source<PositionEvent> src, PositionEvent.Handler handler) {
    Consumer<PositionEvent> adapter = pos -> handler.handle(pos.x(), pos.y());
    bind(src, adapter);
}
```

Finally we define a similar bind variant and handler abstraction for an axis event:

```java
interface Axis {
    @FunctionalInterface
    public interface Handler {
        void handle(float value);
    }
}
```

The new event handling framework and the action bindings class should satisfy the requirements we identified at the start of the chapter:

* The GLFW specifics are now abstracted away (and theoretically could be replaced by an alternative implementation).

* The event-handling logic is separated from the application code, e.g. binding ESCAPE to the stop method.

* Binding events to handlers or methods is relatively concise and does not require any casting or switching logic.

Devices that are implemented using GLFW query methods (such as a gamepad controller or joystick) will be addressed in a later chapter.

---

## Camera Controller

### Default Implementation

The camera class is a simple model class, to implement richer functionality we will introduce a _camera controller_ that can be bound to input actions.

We first implement a basic _free-look_ controller that rotates the scene about the cameras position:

```java
public class DefaultCameraController {
    private final Camera cam;
    private final Dimensions dim;
    
    public void update(float x, float y) {
        ...
    }
}
```

The `update` method accepts an X-Y coordinate relative to the specified viewport dimensions, i.e. the mouse pointer location.  Note that this method matches the signature of `PositionHandler` functional interface.

The view direction of the free-look camera is determined as follows:

1. Map the coordinates to yaw-pitch angles.

2. Calculate a point on the unit-sphere given these angles.

3. Point the camera in the direction of the calculated point.

To transform the coordinates to yaw-pitch angles we add the _interpolator_ class:

```java
@FunctionalInterface
public interface Interpolator {
    /**
     * Applies this interpolator to the given value.
     * @param value Value to be interpolated (assumes normalized)
     * @return Interpolated value
     */
    float interpolate(float t);
    
    static Interpolator linear(float start, float end) {
        float range = end - start;
        return t -> lerp(start, range, t);
    }

    static float lerp(float start, float range, float value) {
        return start + value * range;
    }
}
```

We can now add two interpolators to the controller:

```java
private final Interpolator horizontal = Interpolator.linear(0, TWO_PI);
private final Interpolator vertical = Interpolator.linear(-HALF_PI, HALF_PI);
```

Notes:

* The ranges of the interpolators are dependant on the algorithm to calculate the point on the unit-sphere (see below).

* We may need to make the interpolator ranges mutable, i.e. currently we assume the range is the entire viewport.

* The interpolator class will be expanded with additional functionality in subsequent chapters.

### Unit Sphere

To calculate the point on the unit-sphere we add another new helper class:

```java
public final class Sphere {
    public interface PointFactory {
        /**
         * Calculates the point on the unit-sphere for the given rotation angles (in radians).
         * @param theta     Horizontal angle (or <i>yaw</i>) in the range zero to {@link MathsUtil#TWO_PI}
         * @param phi       Vertical angle (or <i>pitch</i>) in the range +/- {@link MathsUtil#HALF_PI}
         * @return Unit-sphere surface point
         */
        Point point(float theta, float phi);
    }
}
```

The default implementation of the factory method is relatively straight-forward:

```java
PointFactory DEFAULT = (theta, phi) -> {
    final float cos = cos(phi);
    final float x = cos(theta) * cos;
    final float y = sin(theta) * cos;
    final float z = sin(phi);
    return new Point(x, y, z);
};
```

This implementation is based on the standard algorithm for calculating a point on a sphere, however the _coordinate space_ of the generated points is not aligned with the Vulkan system:

1. A horizontal (theta) angle of zero points in the direction of the X axis whereas we generally require the default to be the negative Z axis.

2. The Y and Z axes are transposed, i.e. Z is _up_ in the default implementation of the algorithm.

For these reasons we implement the algorithm as an interface so we can provide adapters to transform the coordinate space, rather than butchering the algorithm or (for example) forcing the client to pass option flags into the method.

To make the camera point in the negative Z direction we simply fiddle the angle with a 90 degree clockwise 'rotation':

```java
default PointFactory rotate() {
    return (theta, phi) -> point(theta - MathsUtil.HALF_PI, phi);
}
```

To transpose the axes we create an adapter to swizzle the Y and Z components of the calculated point:

```java
default PointFactory swizzle() {
    return (theta, phi) -> {
        final Point pt = point(theta, phi);
        return new Point(pt.x, pt.z, pt.y);
    };
}
```

Note that both these adapters are `default` interface methods which allows us to create the desired factory as follows:

```java
public class DefaultCameraController {
    ...
    private final PointFactory sphere = PointFactory.DEFAULT.swizzle().rotate();
}
```

In the unit-test for the new sphere class we use a `spy` to create a mock that automatically implements the default methods:

```java
public class SphereTest {
    @Nested
    class PointFactoryTests {
        @Test
        void rotate() {
            PointFactory factory = spy(PointFactory.class);
            PointFactory rotate = factory.rotate();
            assertNotNull(rotate);
            rotate.point(0, 0);
            verify(factory).point(-HALF_PI, 0);
        }
    }
}
```

Finally we can implement the controller update method to point the camera at the calculated point on the sphere:

```java
public void update(float x, float y) {
    float yaw = horizontal.interpolate(x / dim.width());
    float pitch = vertical.interpolate(y / dim.height());
    Point pt = sphere.point(yaw, pitch);
    cam.direction(new Vector(pt));
}
```

### Orbital Controller

An _orbital_ (or arcball) camera controller rotates the view position _about_ a target point-of-interest.

We first extend the default controller to include the target position and a _radius_ which is the distance from the camera:

```java
public class OrbitalCameraController extends DefaultCameraController {
    private Point target = Point.ORIGIN;
    private float radius = 1;

    public OrbitalCameraController(Camera cam, Dimensions dim) {
        super(cam, dim);
        cam.look(target);
    }
}
```

The algorithm to calculate the position of the camera is the same as the default controller except for the final step, there we factor out that step to a local helper which can the be over-ridden:

```java
public void update(float x, float y) {
    ...
    Point pt = sphere.point(yaw, pitch);
    update(pt);
}

protected void update(Point pos) {
    cam.direction(new Vector(pos));
}
```

In the orbital implementation we override the new method to move the camera to the calculated point on the sphere and then point it at the target:

```java
@Override
protected void update(Point pt) {
    Point pos = pt.scale(radius).add(target);
    cam.move(pos);
    cam.look(target);
}
```

The orbital controller provides mutators (not shown) to set the radius and target, and to clamp the radius to a min/max range (to prevent the camera being moved to the target position).

The orbital camera can also be _zoomed_ towards or away from the target:

```java
public void zoom(float inc) {
    radius = MathsUtil.clamp(radius - inc * scale, min, max);
    Vector pos = cam.direction().multiply(radius);
    cam.move(target.add(pos));
}
```

Note that the increment is _subtracted_ from the radius.

---

## Integration

To integrate the new event framework and camera controller we add the following to the camera configuration class:

```java
public class CameraConfiguration {
    private final Matrix projection;
    private final Camera cam = new Camera();
    private final OrbitalCameraController controller;

    public CameraConfiguration(Swapchain swapchain) {
        projection = Projection.DEFAULT.matrix(0.1f, 100, swapchain.extents());
        controller = new OrbitalCameraController(cam, swapchain.extents());
        controller.radius(3);
        controller.scale(0.25f);
    }
}
```

Next we add a new component to instantiate the action bindings:

```java
@Bean
public ActionBindings bindings(Window window, RenderLoop loop) {
    ActionBindings bindings = new ActionBindings();
    ...
    bindings.init();
    return bindings;
}
```

The ESCAPE key is bound to the `stop` method of the render loop:

```java
KeyboardDevice keyboard = window.keyboard();
bindings.bind(keyboard.key("ESCAPE"), loop::stop);
keyboard.bind(bindings);
```

And the mouse pointer and wheel are bound to the relevant methods on the controller:

```java
MouseDevice mouse = window.mouse();
bindings.bind(mouse.pointer(), controller::update);
bindings.bind(mouse.wheel(), controller::zoom);
```

Finally we modify the matrix bean to apply the local rotation to the chalet model and to calculate the final projection matrix:

```java
@Bean
public Task matrix(VulkanBuffer uniform) {
    Matrix x = Rotation.matrix(Vector.X, MathsUtil.toRadians(90));
    Matrix y = Rotation.matrix(Vector.Y, MathsUtil.toRadians(-120));
    Matrix model = y.multiply(x);

    return () -> {
        final Matrix matrix = projection.multiply(cam.matrix()).multiply(model);
        uniform.load(matrix);
    };
}
```

When we run the application we should now be able to use the mouse to look around the chalet model and zoom in using the scroll wheel.  Nice.

---

## Summary

In this chapter we implemented:

* A generic input event framework that abstracts over the underlying GLFW implementation.

* The action bindings class that aids separation of concerns for input events and application action handlers.

* Free-look and orbital camera controllers.

